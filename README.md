# Interactive Document QA System

This project implements an interactive question-answering system using LlamaIndex, LangChain, and PostgreSQL vector storage. The system allows users to query documents using natural language, with responses generated by the Llama 2 language model.

## Features

- **Interactive Query Interface**: Continuous Q&A session with easy-to-use commands
- **Document Deduplication**: Prevents duplicate document processing using file hashing
- **PostgreSQL Vector Storage**: Efficient storage and retrieval of document embeddings
- **Multilingual Support**: Uses the multilingual-e5-small embedding model
- **Streaming Responses**: Real-time response streaming for better user experience

## Prerequisites

- Python 3.12+
- PostgreSQL database
- Llama 2 model (quantized version: DeepSeek-R1-Distill-Llama-8B-Q4_K_M.gguf) You can use some other model as well.

## Required Python Packages

```bash
langchain
llama-cpp-python
llama-index
psycopg2-binary
transformers
torch
```

## Setup

1. Clone the repository:
```bash
git clone [repository-url]
cd [repository-name]
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Configure PostgreSQL:
- Create a database named 'vector_db'
- Ensure PostgreSQL is running on localhost:5432

4. Place your documents in the `./data` directory

5. Update the configuration in `main()` if needed:
```python
db_config = {
    'host': 'localhost',
    'port': '5432',
    'user': 'postgres',
    'password': 'password',
    'database': 'vector_db'
}
```

## Usage

1. Run the application:
```bash
python main.py
```

2. Enter questions when prompted

3. To exit:
- Type 'exit' or 'quit'
- Press Ctrl+C

## System Architecture

- **Document Processing**: Files are hashed and checked for existence before processing
- **Vector Storage**: Documents are stored in PostgreSQL using pgvector
- **Embedding Model**: multilingual-e5-small for document and query embedding
- **LLM**: Deepseek R1 (8B parameters, quantized) for response generation
- **Chunking**: Documents are split into 256-token chunks with 20-token overlap

## Error Handling

- Graceful handling of document processing errors
- Robust query processing with informative error messages
- Session persistence despite individual query failures

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## License

The source code for the site is licensed under the MIT license, which you can find in the MIT-LICENSE.txt file

## Acknowledgments

- LlamaIndex for the document indexing framework
- LangChain for the LLM integration
- PostgreSQL and pgvector for vector storage
- LAION for the multilingual-e5-small embedding model
